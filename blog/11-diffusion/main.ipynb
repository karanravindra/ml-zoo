{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import tqdm as tqdm\n",
    "from ml_zoo import CelebAHQDataModule, CelebAHQDataModuleConfig, MNISTDataModule, MNISTDataModuleConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm = CelebAHQDataModule(\n",
    "#     CelebAHQDataModuleConfig(\n",
    "#         data_dir=\"data\",\n",
    "#         batch_size=64,\n",
    "#         num_workers=2,\n",
    "#         persistent_workers=True,\n",
    "#         transforms=[\n",
    "#             torchvision.transforms.Resize((32, 32)),\n",
    "#             torchvision.transforms.ToTensor(),\n",
    "#         ],\n",
    "#     )\n",
    "# )\n",
    "dm = MNISTDataModule(\n",
    "    MNISTDataModuleConfig(\n",
    "        data_dir=\"data\",\n",
    "        batch_size=64,\n",
    "        num_workers=2,\n",
    "        persistent_workers=True,\n",
    "        transforms=[\n",
    "            torchvision.transforms.Resize((32, 32)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diffusers\n",
    "\n",
    "scheduler = diffusers.DDIMScheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.time_emb = nn.Embedding(1000, 256)\n",
    "        self.class_emb = nn.Embedding(11, 256)\n",
    "\n",
    "        self.mlp1 = nn.Linear(256, 512)\n",
    "        self.mlp2 = nn.Linear(256, 256)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 32, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 512)\n",
    "        self.fc5 = nn.Linear(512, 32 * 32)\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "        y_emb = self.class_emb(y)\n",
    "        t_emb = self.time_emb(t)\n",
    "\n",
    "        mlp1_out = F.relu(self.mlp1(y_emb + t_emb))\n",
    "        mlp2_out = F.relu(self.mlp2(y_emb + t_emb))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        identity = x\n",
    "        x = F.relu(self.fc1(x)) + mlp1_out\n",
    "        x = F.relu(self.fc2(x)) + mlp2_out\n",
    "        x = F.relu(self.fc3(x)) + mlp2_out\n",
    "        x = F.relu(self.fc4(x)) + mlp1_out\n",
    "        x = self.fc5(x)\n",
    "        x = identity - x\n",
    "        return x.view(x.size(0), 1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 1,835,008 parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(\"mps\")\n",
    "\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(steps=50):\n",
    "    model.eval()\n",
    "    noise = torch.randn((33, 1, 32, 32), device=\"mps\")\n",
    "    y = torch.arange(11, device=noise.device).repeat(3)\n",
    "    t_steps = torch.arange(0, 1000, 1000//steps, device=noise.device)\n",
    "\n",
    "    scheduler.set_timesteps(steps)\n",
    "    for t in reversed(t_steps):\n",
    "        t_s = torch.full((y.shape[0],), t, device=noise.device)\n",
    "        out = model(noise, y, t_s).view(-1, 1, 32, 32)\n",
    "        img = scheduler.step(out, t, noise, eta=0).prev_sample\n",
    "        \n",
    "    torchvision.utils.save_image(img.view(-1, 1, 32, 32), \"samples.png\", nrow=11)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate():\n",
    "    model.eval()\n",
    "    t_loss = torch.tensor(0.0, device=\"mps\")\n",
    "    for x, y in val_loader:\n",
    "        x, y = x.to(\"mps\"), y.to(\"mps\")\n",
    "        # y += 1\n",
    "\n",
    "        noise = torch.randn_like(x)\n",
    "\n",
    "        t = torch.randint(0, 1000, (x.shape[0],), device=x.device)\n",
    "        noisy_x = scheduler.add_noise(x, noise, t)\n",
    "\n",
    "        out = model(noisy_x, y, t)\n",
    "        loss = F.mse_loss(out, noise)\n",
    "        t_loss += loss\n",
    "    return t_loss.item() / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_pytorch import EMA\n",
    "ema = EMA(model, beta=0.9999, update_after_step=100, update_every=1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=6e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 1, 32, 32]) torch.Size([4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 821/240000 [00:28<2:18:47, 28.72it/s, loss=0.112]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m ema\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m---> 21\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     24\u001b[0m     generate()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to(\"mps\"), y.to(\"mps\")\n",
    "\n",
    "x, y = x.repeat(64, 1, 1, 1), y.repeat(64)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "pbar = tqdm.trange(240_000)\n",
    "for i in pbar:\n",
    "    noise = torch.randn_like(x)\n",
    "    t = torch.randint(0, 1000, (x.shape[0],), device=x.device)\n",
    "\n",
    "    noisy_x = scheduler.add_noise(x, noise, t)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(noisy_x, y, t)\n",
    "    loss = F.mse_loss(out, noise)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    ema.update()\n",
    "    \n",
    "    pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    generate()\n",
    "    val_loss = validate()\n",
    "\n",
    "    model.train()\n",
    "    pbar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(\"mps\"), y.to(\"mps\")\n",
    "        \n",
    "        # y = F.dropout(y.float(), 0.1).long()\n",
    "        noise = torch.randn_like(x)\n",
    "\n",
    "        t = torch.randint(0, scheduler.config.num_train_timesteps, (x.shape[0],), device=x.device)\n",
    "        noisy_x = scheduler.add_noise(x, noise, t)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(noisy_x, y, t)\n",
    "        loss = F.mse_loss(out, noise)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ema.update()\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item(), val_loss=val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
